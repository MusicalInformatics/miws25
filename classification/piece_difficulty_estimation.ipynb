{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piece Difficulty Estimation\n",
    "\n",
    "In this notebook we are going to explore predicting piece difficulty for piano pieces using \"classical\" machine learning techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import partitura as pt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from classification_utils import plot_confusion_matrix\n",
    "\n",
    "\n",
    "# Increase the recursion limit\n",
    "# This is necessary for pickling scores\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"partitura\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"sklearn\")\n",
    "\n",
    "# Replace the with the path where you downloaded the data\n",
    "# PATH_TO_DATASET = \"scores_difficulty_estimation\"\n",
    "PATH_TO_DATASET = \"datasets/scores_difficulty_estimation\"\n",
    "PATH_TO_LABELS = \"difficulty_classification_training.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH_TO_LABELS)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of each unique category\n",
    "value_counts = data[\"difficulty\"].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.bar(\n",
    "    value_counts.index,\n",
    "    value_counts.values,\n",
    "    color=\"firebrick\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"Difficulty\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this path with the one where you downloaded the data\n",
    "# cached_scores_dir = \"pickled_scores_difficulty_estimation\"\n",
    "cached_scores_dir = \"./datasets/pickled_scores_difficulty_estimation\"\n",
    "\n",
    "if not os.path.exists(cached_scores_dir):\n",
    "    os.mkdir(cached_scores_dir)\n",
    "\n",
    "scores = []\n",
    "score_names = []\n",
    "difficulty = []\n",
    "for i, (score_name, dif) in enumerate(zip(data[\"file\"], data[\"difficulty\"])):\n",
    "\n",
    "    pickled_score_fn = os.path.join(cached_scores_dir, f\"{score_name}.pyc\")\n",
    "    score_fn = os.path.join(PATH_TO_DATASET, score_name)\n",
    "\n",
    "    if not os.path.exists(pickled_score_fn):\n",
    "        score = pt.load_musicxml(score_fn)\n",
    "\n",
    "        with open(pickled_score_fn, \"wb\") as f:\n",
    "            print(f\"saving {score_name}\")\n",
    "            pickle.dump(score, f)\n",
    "\n",
    "    else:\n",
    "        with open(pickled_score_fn, \"rb\") as f:\n",
    "            score = pickle.load(f)\n",
    "\n",
    "    scores.append(score)\n",
    "    score_names.append(score_name)\n",
    "    difficulty.append(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    score[0].use_musical_beat()\n",
    "scores = np.array(scores, dtype=object)\n",
    "score_names = np.array(score_names)\n",
    "difficulty = np.array(difficulty)\n",
    "\n",
    "extended_score_note_array = pt.utils.music.ensure_notearray(\n",
    "    score,\n",
    "    include_pitch_spelling=True,  # adds 3 fields: step, alter, octave\n",
    "    include_key_signature=True,  # adds 2 fields: ks_fifths, ks_mode\n",
    "    include_time_signature=True,  # adds 2 fields: ts_beats, ts_beat_type\n",
    "    include_metrical_position=True,  # adds 3 fields: is_downbeat, rel_onset_div, tot_measure_div\n",
    "    include_grace_notes=True,  # adds 2 fields: is_grace, grace_type\n",
    ")\n",
    "\n",
    "note_arrays = np.array(\n",
    "    [\n",
    "        pt.utils.music.ensure_notearray(\n",
    "            score,\n",
    "            include_pitch_spelling=True,  # adds 3 fields: step, alter, octave\n",
    "            include_key_signature=True,  # adds 2 fields: ks_fifths, ks_mode\n",
    "            include_time_signature=True,  # adds 2 fields: ts_beats, ts_beat_type\n",
    "            include_metrical_position=True,  # adds 3 fields: is_downbeat, rel_onset_div, tot_measure_div\n",
    "            include_grace_notes=True,  # adds 2 fields: is_grace, grace_type\n",
    "        )\n",
    "        for score in scores\n",
    "    ],\n",
    "    dtype=object,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets with stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "na_train_val, na_test, di_train_val, di_test = train_test_split(\n",
    "    note_arrays,\n",
    "    difficulty,\n",
    "    test_size=test_size,\n",
    "    stratify=difficulty,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_size = 0.1\n",
    "na_train, na_val, di_train, di_val = train_test_split(\n",
    "    na_train_val,\n",
    "    di_train_val,\n",
    "    test_size=val_size,\n",
    "    stratify=di_train_val,\n",
    "    random_state=1942,\n",
    ")\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(f\"X_train shape: {na_train.shape}, Y_train shape: {di_train.shape}\")\n",
    "print(f\"X_val shape: {na_val.shape}, Y_val shape: {di_val.shape}\")\n",
    "print(f\"X_test shape: {na_test.shape}, Y_test shape: {di_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from partitura.musicanalysis.note_features import list_note_feats_functions\n",
    "\n",
    "\n",
    "note_feats_functions = list_note_feats_functions()\n",
    "\n",
    "for nff in note_feats_functions:\n",
    "    print(nff)\n",
    "\n",
    "\n",
    "def compute_note_density(score: Union[pt.score.ScoreLike, np.ndarray]) -> float:\n",
    "\n",
    "    if isinstance(score, (pt.score.Score, pt.score.Part)):\n",
    "\n",
    "        note_array = score.note_array()\n",
    "    elif isinstance(score, np.ndarray):\n",
    "        note_array = score\n",
    "\n",
    "    piece_duration_beats = (\n",
    "        note_array[\"onset_beat\"] + note_array[\"duration_beat\"]\n",
    "    ).max() - note_array[\"onset_beat\"].min()\n",
    "\n",
    "    number_of_notes = len(note_array)\n",
    "\n",
    "    note_density = number_of_notes / piece_duration_beats\n",
    "\n",
    "    return note_density\n",
    "\n",
    "\n",
    "def compute_piece_length(score: Union[pt.score.ScoreLike, np.ndarray]) -> float:\n",
    "\n",
    "    if isinstance(score, (pt.score.Score, pt.score.Part)):\n",
    "\n",
    "        note_array = score.note_array()\n",
    "    elif isinstance(score, np.ndarray):\n",
    "        note_array = score\n",
    "\n",
    "    piece_duration_beats = (\n",
    "        note_array[\"onset_beat\"] + note_array[\"duration_beat\"]\n",
    "    ).max() - note_array[\"onset_beat\"].min()\n",
    "\n",
    "    return piece_duration_beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "note_densities = np.array([compute_note_density(na) for na in na_train])\n",
    "\n",
    "plt.scatter(\n",
    "    note_densities,\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "\n",
    "duration_corr = np.corrcoef(note_densities, di_train)[0, 1]\n",
    "plt.title(f\"Note density vs. Difficulty ($r = {duration_corr:0.2f}$)\")\n",
    "plt.xlabel(\"Note density (notes per beat)\")\n",
    "plt.ylabel(\"Difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_duration = np.array([compute_piece_length(na) for na in na_train])\n",
    "\n",
    "plt.scatter(\n",
    "    piece_duration,\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "duration_corr = np.corrcoef(piece_duration, di_train)[0, 1]\n",
    "plt.xlabel(\"Piece duration (beats)\")\n",
    "plt.ylabel(\"Difficulty\")\n",
    "plt.title(f\"Piece duration vs. Difficulty ($r = {duration_corr:0.2f}$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from partitura.musicanalysis.note_features import vertical_neighbor_feature\n",
    "\n",
    "\n",
    "def compute_vertical_neighbors(\n",
    "    score: Union[pt.score.ScoreLike, np.ndarray]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Vertical neighbor feature.\n",
    "\n",
    "    Describes various aspects of simultaneously starting notes.\n",
    "\n",
    "    Returns:\n",
    "    * n_total :\n",
    "    * n_above :\n",
    "    * n_below :\n",
    "    * highest_pitch :\n",
    "    * lowest_pitch :\n",
    "    * pitch_range :\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(score, (pt.score.Score, pt.score.Part)):\n",
    "\n",
    "        na = score.note_array()\n",
    "    elif isinstance(score, np.ndarray):\n",
    "        na = score\n",
    "    # the list of descriptors\n",
    "    names = [\n",
    "        \"n_total\",\n",
    "        \"n_above\",\n",
    "        \"n_below\",\n",
    "        \"highest_pitch\",\n",
    "        \"lowest_pitch\",\n",
    "        \"pitch_range\",\n",
    "    ]\n",
    "    W = np.zeros((len(na), len(names)))\n",
    "    for i, n in enumerate(na):\n",
    "        neighbors = na[np.where(na[\"onset_beat\"] == n[\"onset_beat\"])][\"pitch\"]\n",
    "        max_pitch = np.max(neighbors)\n",
    "        min_pitch = np.min(neighbors)\n",
    "        W[i, 0] = len(neighbors) - 1\n",
    "        W[i, 1] = np.sum(neighbors > n[\"pitch\"])\n",
    "        W[i, 2] = np.sum(neighbors < n[\"pitch\"])\n",
    "        W[i, 3] = max_pitch\n",
    "        W[i, 4] = min_pitch\n",
    "        W[i, 5] = max_pitch - min_pitch\n",
    "\n",
    "    vertical_neighbors = W.mean(0)\n",
    "    return vertical_neighbors\n",
    "\n",
    "\n",
    "vertical_neighbors = np.array([compute_vertical_neighbors(na) for na in na_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharey=True, figsize=(10, 7))\n",
    "\n",
    "axes[0, 0].scatter(\n",
    "    vertical_neighbors[:, 0],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"n total\")\n",
    "total_neighbors_corr = np.corrcoef(vertical_neighbors[:, 0], di_train)[0, 1]\n",
    "axes[0, 0].set_ylabel(\"Difficulty\")\n",
    "axes[0, 0].set_title(f\"($r = {total_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "\n",
    "axes[0, 1].scatter(\n",
    "    vertical_neighbors[:, 1],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"n above\")\n",
    "above_neighbors_corr = np.corrcoef(vertical_neighbors[:, 1], di_train)[0, 1]\n",
    "axes[0, 1].set_ylabel(\"Difficulty\")\n",
    "axes[0, 1].set_title(f\"($r = {above_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "\n",
    "axes[0, 2].scatter(\n",
    "    vertical_neighbors[:, 2],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[0, 2].set_xlabel(\"n above\")\n",
    "above_neighbors_corr = np.corrcoef(vertical_neighbors[:, 2], di_train)[0, 1]\n",
    "axes[0, 2].set_ylabel(\"Difficulty\")\n",
    "axes[0, 2].set_title(f\"($r = {above_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "axes[1, 0].scatter(\n",
    "    vertical_neighbors[:, 3],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"highest pitch\")\n",
    "above_neighbors_corr = np.corrcoef(vertical_neighbors[:, 3], di_train)[0, 1]\n",
    "axes[1, 0].set_ylabel(\"Difficulty\")\n",
    "axes[1, 0].set_title(f\"($r = {above_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "axes[1, 1].scatter(\n",
    "    vertical_neighbors[:, 4],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[1, 1].set_xlabel(\"lowest pitch\")\n",
    "above_neighbors_corr = np.corrcoef(vertical_neighbors[:, 4], di_train)[0, 1]\n",
    "axes[1, 1].set_ylabel(\"Difficulty\")\n",
    "axes[1, 1].set_title(f\"($r = {above_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "axes[1, 2].scatter(\n",
    "    vertical_neighbors[:, 5],\n",
    "    di_train,\n",
    "    s=50,  # Marker size\n",
    "    facecolors=\"none\",  # Unfilled markers\n",
    "    edgecolors=\"firebrick\",  # Marker edge color\n",
    "    marker=\"o\",\n",
    ")\n",
    "axes[1, 2].set_xlabel(\"lowest pitch\")\n",
    "above_neighbors_corr = np.corrcoef(vertical_neighbors[:, 5], di_train)[0, 1]\n",
    "axes[1, 2].set_ylabel(\"Difficulty\")\n",
    "axes[1, 2].set_title(f\"($r = {above_neighbors_corr:0.2f}$)\")\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score_features(\n",
    "    score: Union[pt.score.Score, pt.score.Part, np.ndarray]\n",
    ") -> np.ndarray:\n",
    "\n",
    "    if isinstance(score, (pt.score.Score, pt.score.Part)):\n",
    "\n",
    "        na = score.note_array()\n",
    "    elif isinstance(score, np.ndarray):\n",
    "        na = score\n",
    "\n",
    "    ## TODO: Compute all features here\n",
    "    # Decide which features might be more relevant\n",
    "\n",
    "    note_density = compute_note_density(na)\n",
    "    piece_duration = compute_piece_length(na)\n",
    "    vertical_neighbors = compute_vertical_neighbors(na)\n",
    "\n",
    "    features = np.r_[note_density, piece_duration, vertical_neighbors]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are not using a method with hyperparameters, we can use the entire training set.\n",
    "# otherwise\n",
    "# X_train = np.array([compute_score_features(na) for na in na_train])\n",
    "X_train = np.array([compute_score_features(na) for na in na_train_val])\n",
    "# if we need validation\n",
    "# X_val = np.array([compute_score_features(na) for na in na_val])\n",
    "\n",
    "X_test = np.array([compute_score_features(na) for na in na_test])\n",
    "\n",
    "Y_train = di_train_val\n",
    "Y_test = di_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Baseline\": DummyClassifier(strategy='most_frequent'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name} classifier.\")\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # Predict on test set\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    # Evaluate the classifier\n",
    "    acc = accuracy_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"macro\")\n",
    "    plot_confusion_matrix(predictions=Y_pred, targets=Y_test, class_names=[f\"{i}\" for i in range(1, 10)])\n",
    "    print(f\"Accuracy of {name}: {acc:.2f}\")\n",
    "    print(f\"Macro F1-score {name}: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miws25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
